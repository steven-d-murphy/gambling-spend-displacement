{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use ChatGPT to classify transaction data\n",
    "\n",
    "Use this file for testing the API and prompt tuning\n",
    "\n",
    "Before you start, make sure you have an API key setup:\n",
    "+ Go to https://platform.openai.com/api-keys\n",
    "+ Generate key\n",
    "+ Open PowerShell\n",
    "+ Run: setx OPENAI_API_KEY \"the-key-you-just-generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os, zipfile, json, tiktoken, statistics\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "\n",
    "model = \"gpt-4o\"  # More expensive, older and doesn't support structured outputs or batching\n",
    "model = \"o4-mini\" # Use this - it is slightly slower, but has more recent training data and supports structured outputs\n",
    "\n",
    "# Output class component\n",
    "class ReturnComponent(BaseModel):\n",
    "    index: int\n",
    "    brand: str\n",
    "    code: float\n",
    "    confidence: float\n",
    "    note: str\n",
    "\n",
    "# Output class\n",
    "class ClassificationReturn(BaseModel):\n",
    "    values: list[ReturnComponent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found API key with length 164\n"
     ]
    }
   ],
   "source": [
    "try: # Check we have the API key installed\n",
    "    apiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "    print(f'Found API key with length {len(apiKey)}')\n",
    "except:\n",
    "    print('Cannot find OPENAI_API_KEY environment variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test to see we can call the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont= \"\"\"\n",
    "Hi, could you provide a list of the first five primes, triangular numbers, squares and cubes please.\n",
    "Format your response as a table that I can easily read into a pandas dataframe\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a simple CSV‐style table you can feed directly into pandas (e.g. via pd.read_csv or pd.read_table with sep=\",\"):\n",
      "\n",
      "prime,triangular,square,cube  \n",
      "2,1,1,1  \n",
      "3,3,4,8  \n",
      "5,6,9,27  \n",
      "7,10,16,64  \n",
      "11,15,25,125  \n",
      "\n",
      "Example in pandas:\n",
      "\n",
      "```\n",
      "import pandas as pd\n",
      "from io import StringIO\n",
      "\n",
      "data = \"\"\"prime,triangular,square,cube\n",
      "2,1,1,1\n",
      "3,3,4,8\n",
      "5,6,9,27\n",
      "7,10,16,64\n",
      "11,15,25,125\n",
      "\"\"\"\n",
      "\n",
      "df = pd.read_csv(StringIO(data))\n",
      "print(df)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model, \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": cont}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get inputs to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 20 thousand brands\n",
    "df = pd.read_parquet('top_20K.parquet')\n",
    "\n",
    "# System message\n",
    "system_message_content =  open(\"system_message.txt\", \"r\", encoding=\"utf-8\").read() # This reads : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a transaction–brand classifier for UK bank data. Use the following bespoke COICOP-derived scheme:\n",
    "\n",
    "Codes:\n",
    "+ -1.00: Income – Wages, salaries, government benefits, charitable receipts (excludes dissaving/investment returns).\n",
    "+ + -1.10: Wages and salaries – Income from labour.\n",
    "+ + -1.20: Entitlements/benefits – Government benefit payments.\n",
    "+ + -1.30: Charitable payments – Charitable receipts.\n",
    "\n",
    "+ 0.00: Unclassified – Unidentifiable or net-zero transactions.\n",
    "+ + 0.10: Internal transfers – Between same individual’s accounts; exclude purpose-specific transfers (e.g. savings).\n",
    "+ + 0.20: No brand or unrecognised brands – Inc. ATM, payment providers and alphanumeric codes; truly multi-category brands → 13.10.\n",
    "\n",
    "+ 1.00: Food & non-alcoholic beverages. (inc. supermarkets)\n",
    "+ 2.00: Alcoholic beverages, tobacco & narcotics. (including off-licences)\n",
    "+ 3.00: Clothing & footwear.\n",
    "+ 4.00: Housing, water, electricity, gas & other fuels (incl. rent/mortgage).\n",
    "+ 5.00: Furnishings, household equipment & maintenance.\n",
    "+ 6.00: Health.\n",
    "+ 7.00: Transport (incl. car-loan repayments and postal costs).\n",
    "+ 8.00: Information & communication.\n",
    "+ 9.00: Recreation, sport & culture (gambling extracted).\n",
    "+ 10.00: Education services (incl. tuition & student-loan repayments).\n",
    "+ 11.00: Restaurants & accommodation services.\n",
    "\n",
    "+ 12.00: Insurance & financial services.\n",
    "+ + 12.10: Insurance – Premiums & claim payouts.\n",
    "+ + 12.20: Financial services general. (Inc. non-credit card account charges and overdraft interest) \n",
    "+ + 12.21: Credit cards – Fees & interest only; purchases go to merchant category.\n",
    "+ + 12.22: Savings – Transfers into savings. (including no/unrecognised bands that indicate an intention to save)\n",
    "+ + 12.23: Investments – Transactions with investment providers.\n",
    "+ + 12.24: Pensions – Pension contributions & payouts.\n",
    "+ + 12.25: Loans – Loan receipts & repayments; **if any other purpose is implied** (car, mortgage, home improvement, business, etc.), classify to that purpose’s code instead.\n",
    "\n",
    "+ 13.00: Personal care, social protection & misc. goods & services.\n",
    "+ + 13.10: General purpose retailers – Truly multi-category (e.g. Amazon).\n",
    "+ + 13.20: Taxes – Payments & rebates. (Unless tax for a specific purpose, such as property taxes → 4.0, or vehicle taxes → 7.0)\n",
    "+ + 13.30: Political donations and charitable giving\n",
    "\n",
    "+ 14.00: Gambling (except lotteries)\n",
    "+ 15.00: Lotteries\n",
    "\n",
    "**COICOP overlap**\n",
    "\n",
    "Codes 1 to 11 align with COICOP 2018: https://unstats.un.org/unsd/classifications/unsdclassifications/COICOP_2018_-_pre-edited_white_cover_version_-_2018-12-26.pdf\n",
    "Reference this to resolve difficulties. Exception: gambling moved from 9 to 14 and 15.\n",
    "\n",
    "**Dominant-product rule:**  \n",
    "\n",
    "By default, assign each brand to its primary/dominant category. If a specific product or purpose is explicitly mentioned in the _brand_ (e.g. “car loan”), classify to that product’s code rather than the brand’s default.\n",
    "\n",
    "**Prioritising input information**\n",
    "\n",
    "The descriptions are there as supporting information. If it is clear from the brand alone how to classify, do so. If this cannot be done, then make a judgement based on the descriptions. Weight each description equally, but the brand name highest.\n",
    "\n",
    "**Limiting output information**\n",
    "\n",
    "There is an output field, 'note'. This should almost always be blank. Only provide information about difficult judgement calls.\n",
    "\n",
    "**Classification clarifications**\n",
    "\n",
    "These results will be joined to millions of transactions on the 'brand'. Therefore, you should weight what you know about the brand much more highly than what you see in the descriptions. \n",
    "+ If the brand is best known for credit cards, always classify to 12.21 (such as Barclaycard, AMEX and others)\n",
    "+ Stationary, greetings cards, news and book stores go to 9\n",
    "+ Large banks such as Barclays and Halifax → 12.20, if the brand contains no information about the financial product used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def get_chatgpt_return(client, model, system_message_content, in_df):\n",
    "    records_json = dataframe_to_api_records(in_df)\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\"role\":\"system\", \"content\": system_message_content},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": records_json,\n",
    "            },\n",
    "        ],\n",
    "        text_format=ClassificationReturn,\n",
    "    )\n",
    "    event = response.output_parsed\n",
    "    out_df = pd.DataFrame([comp.model_dump() for comp in event.values]).set_index('index', drop=True)   \n",
    "    return response, out_df\n",
    "\n",
    "def dataframe_to_api_records(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame into the JSON string for the `records` argument\n",
    "    of the classify_brands function.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    # Iterate over rows in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        # Collect up to three description fields (adjust if you have more/less)\n",
    "        descriptions = [\n",
    "            row.get('description1'),\n",
    "            row.get('description2'),\n",
    "            row.get('description3')\n",
    "        ]\n",
    "        # Filter out any missing or NaN descriptions\n",
    "        descriptions = [desc for desc in descriptions if pd.notna(desc)]\n",
    "        \n",
    "        record = {\n",
    "            \"index\": int(idx),\n",
    "            \"brand\": row['brand'],\n",
    "            \"descriptions\": descriptions\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    # Convert to a JSON-formatted string\n",
    "    return json.dumps({\"records\": records}, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_content =  open(\"system_message.txt\", \"r\", encoding=\"utf-8\").read() # Get latest version of system prompt\n",
    "\n",
    "# Try a few random transactions\n",
    "in_df = df.iloc[:1000].sample(10)\n",
    "response, out_df = get_chatgpt_return(client, model, system_message_content, in_df)\n",
    "in_out_df = pd.merge(out_df, in_df, left_index=True, right_index=True)\n",
    "in_out_df.to_excel('test_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT returned for 10 records\t(1601,1745,3346) tokens\t 0,\t amazon,\t through 10,\t transport london\n",
      "ChatGPT returned for 20 records\t(2092,3274,5366) tokens\t 10,\t morrisons,\t through 30,\t eat\n",
      "ChatGPT returned for 30 records\t(2604,3472,6076) tokens\t 30,\t revolut,\t through 60,\t amex\n",
      "ChatGPT returned for 40 records\t(3062,3391,6453) tokens\t 60,\t netflix,\t through 100,\t mobilechannel ft\n",
      "ChatGPT returned for 50 records\t(3732,5649,9381) tokens\t 100,\t argos,\t through 150,\t giffgaff\n",
      "ChatGPT returned for 60 records\t(4061,5312,9373) tokens\t 150,\t ikea,\t through 210,\t utilita energy\n",
      "ChatGPT returned for 70 records\t(4773,7119,11892) tokens\t 210,\t nandos,\t through 280,\t currys\n",
      "ChatGPT returned for 80 records\t(5380,6949,12329) tokens\t 280,\t account fee,\t through 360,\t burton\n",
      "ChatGPT returned for 90 records\t(5845,7453,13298) tokens\t 360,\t pbz,\t through 450,\t national health service\n",
      "ChatGPT returned for 100 records\t(6173,8689,14862) tokens\t 450,\t centra,\t through 550,\t kings arms\n"
     ]
    }
   ],
   "source": [
    "# Vary number of records to work out how many records we use for each call\n",
    "inc = 0\n",
    "rdf = []\n",
    "responses = []\n",
    "for i in range(10, 101, 10):\n",
    "    imin = inc\n",
    "    imax = inc + i\n",
    "    inc = imax\n",
    "    in_df = df.iloc[imin:imax]\n",
    "\n",
    "    response, out_df = get_chatgpt_return(client, model, system_message_content, in_df)\n",
    "    \n",
    "    intok = response.usage.input_tokens\n",
    "    outtok = response.usage.output_tokens\n",
    "\n",
    "    print(f'ChatGPT returned for {i} records\\t({intok},{outtok},{intok+outtok}) tokens\\t {imin},\\t {in_df.iloc[0,0]},\\t through {imax},\\t {in_df.iloc[-1,0]}')\n",
    "\n",
    "    rdf += [pd.merge(out_df, in_df, left_index=True, right_index=True)]\n",
    "    pd.concat(rdf).to_excel('test_output.xlsx')\n",
    "    responses += [response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 misalignments\n"
     ]
    }
   ],
   "source": [
    "# Does the return match the input?\n",
    "rdf = pd.concat(rdf)\n",
    "print(sum(rdf.brand_x != rdf.brand_y), 'misalignments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316 2078 3394\n",
      "1807 3934 5741\n",
      "2319 4063 6382\n",
      "2777 6167 8944\n",
      "3447 4811 8258\n",
      "3776 5816 9592\n",
      "4488 5219 9707\n",
      "5095 7744 12839\n",
      "5560 7912 13472\n",
      "5888 9694 15582\n"
     ]
    }
   ],
   "source": [
    "# response_tokens = enc.encode(response)\n",
    "for response in responses:\n",
    "    intok = response.usage.input_tokens\n",
    "    outtok = response.usage.output_tokens\n",
    "    print(intok, outtok, intok+outtok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "displacement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
